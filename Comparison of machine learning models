import warnings
warnings.simplefilter(action="ignore")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Algorithms
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.decomposition import PCA
from xgboost import XGBClassifier

# Rotation Forest Classifier
class RotationForest:
    def __init__(self, base_classifier, n_classifiers, n_features_subset):
        self.base_classifier = base_classifier
        self.n_classifiers = n_classifiers
        self.n_features_subset = n_features_subset
        self.models = []
        self.pca_transformers = []

    def fit(self, X, y):
        for _ in range(self.n_classifiers):
            feature_indices = np.random.choice(X.shape[1], self.n_features_subset, replace=False)
            X_subset = X[:, feature_indices]
            pca = PCA()
            X_rotated = pca.fit_transform(X_subset)
            model = self.base_classifier()
            model.fit(X_rotated, y)
            self.models.append(model)
            self.pca_transformers.append((pca, feature_indices))

    def predict(self, X):
        predictions = np.zeros((X.shape[0], self.n_classifiers))
        for i, (model, (pca, feature_indices)) in enumerate(zip(self.models, self.pca_transformers)):
            X_subset = X[:, feature_indices]
            X_rotated = pca.transform(X_subset)
            predictions[:, i] = model.predict(X_rotated)
        y_pred = np.apply_along_axis(lambda x: np.bincount(x.astype(int)).argmax(), axis=1, arr=predictions)
        return y_pred

# Load the dataset
file_path = 'Maternal Health Risk Data Set.csv'
data = pd.read_csv(file_path)

# Display the first few rows and summary statistics
print(data.head())
print(data.describe())

# Preprocessing: Encode 'RiskLevel' as a numeric target variable
data['RiskLevel_encoded'] = pd.factorize(data['RiskLevel'])[0]

# Check for missing values and handle them (if any)
print(data.isnull().sum())

# Separate numeric and categorical columns
numeric_cols = data.select_dtypes(include=np.number).columns.tolist()
categorical_cols = data.select_dtypes(exclude=np.number).columns.tolist()

# Fill missing values for numeric columns with their mean
data[numeric_cols] = data[numeric_cols].fillna(data[numeric_cols].mean())

# For categorical columns, fill with mode
for col in categorical_cols:
    data[col].fillna(data[col].mode()[0], inplace=True)

# Select features and target
X = data.drop(columns=['RiskLevel', 'RiskLevel_encoded'])
y = data['RiskLevel_encoded']

# Split into train and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Define models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "KNN": KNeighborsClassifier(),
    "Random Forest": RandomForestClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(),
    "SVM": SVC(),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
    "AdaBoost": AdaBoostClassifier(),
    "Naive Bayes": GaussianNB(),
    "Rotation Forest": RotationForest(RandomForestClassifier, n_classifiers=10, n_features_subset=X_train.shape[1] // 2)
}

# Store results in a list
results = []

# Evaluate each model
for name, model in models.items():
    if name == "Rotation Forest":
        model.fit(X_train.values, y_train.values)
        y_pred = model.predict(X_test.values)
        accuracy = np.mean(y_pred == y_test.values)
    else:
        scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')
        accuracy = np.mean(scores)

    # Append the model name and accuracy to the results list
    results.append({"Model": name, "Accuracy": accuracy})

# Convert the results list to a DataFrame
results_df = pd.DataFrame(results)

# Display the results as a table
print("Model Accuracy Comparison:")
print(results_df)

# Visualize the results using a bar plot
plt.figure(figsize=(10, 6))
sns.barplot(x="Accuracy", y="Model", data=results_df, palette='viridis')
plt.title('Model Comparison - Accuracy')
plt.xlabel('Accuracy')
plt.ylabel('Models')
plt.xlim(0, 1)
plt.grid(axis='x')
plt.show()
